import os
import math
import pandas as pd
import requests
from pathlib import Path
from PIL import Image, ImageDraw
import torch
import joblib
from sklearn.preprocessing import StandardScaler
import streamlit as st
import urllib.parse

# -----------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø©
# -----------------------------
st.set_page_config(page_title="Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙØ§Ù‚Ø¯ Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ù„Ù„ÙØ¦Ø© Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠØ©", layout="wide")

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API Ù„Ù„Ù‚Ù…Ø± Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ
API_KEY = "YOUR_API_KEY"
ZOOM = 15
IMG_SIZE = 640
MAP_TYPE = "satellite"

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
IMG_DIR = "images"
DETECTED_DIR = "DETECTED_FIELDS/FIELDS/farms"
MODEL_PATH = "best.pt"
ML_MODEL_PATH = "isolation_forest_model.joblib"
SCALER_PATH = "scaler.joblib"
OUTPUT_EXCEL = "output/detected_low_usage.xlsx"

# Ø­Ø¯ÙˆØ¯ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø·Ø§Ù‚Ø©
capacity_thresholds = {20: 6000, 50: 15000, 70: 21000, 100: 30000, 150: 45000,
                      200: 60000, 300: 90000, 400: 120000, 500: 150000}

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
Path(IMG_DIR).mkdir(parents=True, exist_ok=True)
Path(DETECTED_DIR).mkdir(parents=True, exist_ok=True)
Path("output").mkdir(parents=True, exist_ok=True)

# -----------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
# -----------------------------
@st.cache_resource
def load_models():
    model_yolo = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_PATH)
    model_ml = joblib.load(ML_MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    return model_yolo, model_ml, scaler

model_yolo, model_ml, scaler = load_models()

# -----------------------------
# Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# -----------------------------
def download_image(lat, lon, meter_id):
    img_path = os.path.join(IMG_DIR, f"{meter_id}.png")
    if os.path.exists(img_path):
        return img_path
    base_url = "https://maps.googleapis.com/maps/api/staticmap"
    params = {"center": f"{lat},{lon}", "zoom": ZOOM, "size": f"{IMG_SIZE}x{IMG_SIZE}", "maptype": MAP_TYPE, "key": API_KEY}
    response = requests.get(base_url, params=params)
    if response.status_code == 200:
        with open(img_path, 'wb') as f:
            f.write(response.content)
        return img_path
    return None

def pixel_to_area(lat, box):
    scale = 156543.03392 * abs(math.cos(math.radians(lat))) / (2 ** ZOOM)
    width_m = abs(box[2] - box[0]) * scale
    height_m = abs(box[3] - box[1]) * scale
    return width_m * height_m

def detect_field(img_path, meter_id, info, model):
    results = model(img_path)
    df_result = results.pandas().xyxy[0]
    fields = df_result[df_result["name"] == "field"]
    if not fields.empty:
        confidence = round(fields["confidence"].max() * 100, 2)
        if confidence >= 85:
            image = Image.open(img_path).convert("RGB")
            draw = ImageDraw.Draw(image)
            largest_field = fields.iloc[0]
            box = [largest_field["xmin"], largest_field["ymin"], largest_field["xmax"], largest_field["ymax"]]
            draw.rectangle(box, outline="green", width=3)
            area = pixel_to_area(info['y'], box)
            draw.text((10, 10), f"ID: {meter_id}\nArea: {int(area)} mÂ²", fill="yellow")
            image_path = os.path.join(DETECTED_DIR, f"{meter_id}.png")
            image.save(image_path)
            return confidence, image_path, int(area)
    return None, None, None

def determine_priority(has_field, anomaly, consumption_check, high_priority_condition):
    if high_priority_condition:
        return "Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ù‹Ø§"
    elif has_field and anomaly and consumption_check:
        return "Ù‚ØµÙˆÙ‰"
    elif has_field and (anomaly or consumption_check):
        return "Ù…ØªÙˆØ³Ø·Ø©"
    elif has_field:
        return "Ù…Ù†Ø®ÙØ¶Ø©"
    return "Ø·Ø¨ÙŠØ¹ÙŠØ©"

def predict_loss(info, model_ml, scaler):
    X = [[info["Breaker Capacity"], info["Ø§Ù„ÙƒÙ…ÙŠØ©"]]]
    X_scaled = scaler.transform(X)
    return model_ml.predict(X_scaled)[0]

def generate_whatsapp_share_link(meter_id, confidence, area, location_link, quantity, capacity, office_number, priority):
    message = f"Ø­Ø§Ù„Ø© Ø¹Ø¯Ø§Ø¯ {meter_id}:\nØ§Ù„Ù…ÙƒØªØ¨: {office_number}\nØ£ÙˆÙ„ÙˆÙŠØ©: {priority}\nØ«Ù‚Ø©: {confidence}%\nÙ…Ø³Ø§Ø­Ø©: {area} Ù…Â²\nØ§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ: {quantity}\nØ³Ø¹Ø© Ø§Ù„Ù‚Ø§Ø·Ø¹: {capacity}\nØ§Ù„Ù…ÙˆÙ‚Ø¹: {location_link}"
    return f"https://wa.me/?text={urllib.parse.quote(message)}"

def generate_google_maps_link(lat, lon):
    return f"https://www.google.com/maps?q={lat},{lon}"

# -----------------------------
# ÙˆØ§Ø¬Ù‡Ø© Streamlit
# -----------------------------
st.title("ğŸ” Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙØ§Ù‚Ø¯ Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ù„Ù„ÙØ¦Ø© Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠØ©")

uploaded_file = st.file_uploader("ğŸ“ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)", type=["xlsx"])

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    required_cols = ["Breaker Capacity", "Ø§Ù„ÙƒÙ…ÙŠØ©", "Ø§Ù„Ù…ÙƒØªØ¨", "y", "x", "Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ"]
    if not all(col in df.columns for col in required_cols):
        st.error("Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©.")
        st.stop()

    results = []
    gallery = []
    progress = st.progress(0)

    for idx, row in df.iterrows():
        meter_id, lat, lon = row['Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ'], row['y'], row['x']
        img_path = download_image(lat, lon, meter_id)
        if img_path:
            conf, img_detected, area = detect_field(img_path, meter_id, row, model_yolo)
            if conf:
                anomaly = predict_loss(row, model_ml, scaler)
                limit = capacity_thresholds.get(row['Breaker Capacity'], 0)
                consumption_check = row['Ø§Ù„ÙƒÙ…ÙŠØ©'] < 0.5 * limit
                high_priority_condition = (conf >= 85 and row['Ø§Ù„ÙƒÙ…ÙŠØ©'] == 0) or (row['Breaker Capacity'] < 200)
                priority = determine_priority(conf >= 85, anomaly, consumption_check, high_priority_condition)
                results.append({**row, "Ø§Ù„Ø«Ù‚Ø©": conf, "Ø§Ù„Ù…Ø³Ø§Ø­Ø©": area, "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©": priority})
                gallery.append((conf, priority, img_detected, meter_id, area, lat, lon, row['Ø§Ù„ÙƒÙ…ÙŠØ©'], row['Breaker Capacity'], row['Ø§Ù„Ù…ÙƒØªØ¨']))

        progress.progress((idx+1)/len(df))

    df_final = pd.DataFrame(results)
    df_final.to_excel(OUTPUT_EXCEL, index=False)
    st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", data=open(OUTPUT_EXCEL, "rb"), file_name="results.xlsx")
